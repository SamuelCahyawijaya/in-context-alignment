"""nusacrowd zero-shot prompt.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ru8DyS2ALWfRdkjOPHj-KNjw6Pfa44Nd
"""
import os, sys
sys.path.append(os.path.join(os.path.dirname(__file__), "src"))

import csv
from os.path import exists
import glob
import random

import numpy as np
import pandas as pd
from tqdm import tqdm
from sklearn.metrics import f1_score, accuracy_score, classification_report

import torch
import torch.nn.functional as F
import datasets

from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM

from dataset_utils import load_dataset
from indexer import SimpleDatasetIndexer
from prompter import ICLPrompter, ITCPrompter

DEBUG=False

lang_map = {
    'btk': 'Batak', 'sun': 'Sundanese', 'jav': 'Javanese', 
    'mad': 'Madurese', 'mak': 'Buginese', 'min': 'Minangkabau',
    'amh': 'Amharic', 'hau': 'Hausa', 'ibo': 'Igbo', 'lug': 'Luganda', 'pcm': 'Nigerian Pidgin',
    'sna': 'chShona', 'swa': 'Kiswahili', 'xho': 'isiXhosa', 'yor': 'Yorùbá',
    'aym': 'Aymara', 'bzd': 'Bribri', 'cni': 'Asháninka', 'gn': 'Guaraní', 'hch': 'Wixarika',
    'nah': 'Nahuatl', 'oto': 'Otomí', 'quy': 'Quechua', 'shp': 'Shipibo-Konibo', 'tar': 'Rarámuri',
    'ind': 'Indonesian', 'eng': 'English', 'spa': 'Spanish', 'arb': 'Arabic', 'fra': 'French', 
    'deu': 'German', 'hin': 'Hindi', 'ita': 'Italian', 'por': 'Portuguese'
}

dataset_to_metadata_map = {
    # key: (prompt_template, icl_template, iia_template, icl_keys, iia_keys, x_iia_keys)
    'americasnli-spa': (
        'Predice la etiqueta de implicación del siguiente par de oraciones:\n{context}\n{query}',
        'Premisa: "{premise}"; Hipótesis: "{hypothesis}" => {label}',
        'En {language}, "{premise_1}" significa "{premise_2}" y "{hypothesis_1}" significa "{hypothesis_2}"',
        ['premise', 'hypothesis'], ['premise_1', 'hypothesis_1'], ['premise_2', 'hypothesis_2']
    ),
    'americasnli': (
        'Predict the entailment label of the following pair of sentences:\n{context}\n{query}',
        'Premise: "{premise}"; Hypothesis: "{hypothesis}" => {label}',
        'In {language}, "{premise_1}" means "{premise_2}" and "{hypothesis_1}" means "{hypothesis_2}"',
        ['premise', 'hypothesis'], ['premise_1', 'hypothesis_1'], ['premise_2', 'hypothesis_2']
    ),
    'nusatranslation-ind': (
        'Prediksikan label sentimen dari kalimat berikut:\n{context}\n{query}',
        '{text} => {label}',
        'Dalam bahasa {language}, "{text_1}" artinya "{text_2}"',
        'text', 'text_1', 'text_2'
    ),
    'nusatranslation': (
        'Predict the sentiment label of the following sentence:\n{context}\n{query}',
        '{text} => {label}',
        'In {language}, "{text_1}" means "{text_2}"',
        'text', 'text_1', 'text_2'
    ),
    'masakhanews': (
        'Predict the topic of the following news title:\n{context}\n{query}',
        '{text} => {label}',
        'In {language}, "{text_1}" means "{text_2}"',
        'text', 'text_1', 'text_2'
    ),
    'tweetsentimulti': (
        'Predict the sentiment label of the following tweet:\n{context}\n{query}',
        '{text} => {label}',
        'In {language}, "{text_1}" means "{text_2}"',
        'text', 'text_1', 'text_2'
    ),
}

def generate_input_label(prompts, labels):
    inputs = []
    for label, prompt in zip(labels, prompts):
        inputs.append(prompt.replace('[LABELS_CHOICE]', label))
    return inputs

if __name__ == '__main__':
    if len(sys.argv) < 2:
        raise ValueError('main_icl_alignment.py <model_path_or_name> <dataset_name> <icl_type> <icl_index_type> <icl_num_exemplar> <iia_type> <iia_index_type> <iia_num_exemplar> <ioa_type> <alignment_position> <batch_size>')

    BASE_PATH='./dataset'
    MODEL = sys.argv[1]
    DATASET_NAME = sys.argv[2] # americasnli, nusatranslation, masakhanews
    ICL_TYPE = sys.argv[3] # cross, mono, none
    ICL_INDEX_TYPE = sys.argv[4].split(',') # random, count, tf-idf, sbert
    ICL_EXEMPLAR_COUNT = int(sys.argv[5])
    IIA_TYPE = sys.argv[6] # cross, mono, none
    IIA_INDEX_TYPE = sys.argv[7].split(',') # random, count, tf-idf, sbert
    IIA_EXEMPLAR_COUNT = int(sys.argv[8])
    IOA_TYPE = sys.argv[9] # True => IOA, Target => No IOA, using Target Label, False => No IOA, using Source Label
    ALIGN_POS = sys.argv[10] # alignment_position "before" or "after" icl_exemplars
    BATCH_SIZE= int(sys.argv[11])

    # Load Dataset
    eval_dsets, icl_dsets, xicl_lang, iia_dsets, itc_dsets, ioa_df = load_dataset(dataset=DATASET_NAME, base_path=BASE_PATH)

    metrics = {
        'dataset': [], 'lang': [],
        'accuracy': [], 'macro_f1': [], 'weighted_f1': []
    }
    
    print('MODEL', MODEL)
    print('DATASET_NAME', DATASET_NAME)
    print('ICL_TYPE', ICL_TYPE)
    print('ICL_INDEX_TYPE', ICL_INDEX_TYPE)
    print('ICL_EXEMPLAR_COUNT', ICL_EXEMPLAR_COUNT)
    print('IIA_TYPE', IIA_TYPE)
    print('IIA_INDEX_TYPE', IIA_INDEX_TYPE)
    print('IIA_EXEMPLAR_COUNT', IIA_EXEMPLAR_COUNT)
    print('IOA_TYPE', IOA_TYPE)
    print('ALIGN_POS', ALIGN_POS)
    print('BATCH_SIZE', BATCH_SIZE)
    
    for dset_lang, eval_dset in eval_dsets.items():
        if dset_lang == 'eng':
            continue
        if IOA_TYPE in ['True', 'Target'] and dset_lang not in ioa_df.index:
            continue

        print(f'== {DATASET_NAME} {dset_lang} ==')

        ###
        # Preprocessing
        ###

        # Extract Metadata
        prompt_template, icl_template, iia_template, icl_keys, iia_keys, x_iia_keys = dataset_to_metadata_map[DATASET_NAME]
        
        # Prepare Prompter
        icl_prompter = ICLPrompter(
            prompt_template=prompt_template, icl_template=icl_template, iia_template=iia_template, alignment_position=ALIGN_POS
        )

        # Retrieve & preprocess labels
        label_names = list(set(eval_dset['label']))
        if IOA_TYPE in ['True', 'Target']:
            label_map = ioa_df.loc[dset_lang, 'label_map']
        else:
            label_map = None
        
        ###
        # Indexing
        ###
        if ICL_TYPE == 'cross':
            icl_dset = icl_dsets[xicl_lang]    
            icl_indexer = SimpleDatasetIndexer(dataset=icl_dset, index_key=icl_keys, index_type=ICL_INDEX_TYPE)
        elif ICL_TYPE == 'mono':
            icl_dset = icl_dsets[dset_lang]    
            icl_indexer = SimpleDatasetIndexer(dataset=icl_dset, index_key=icl_keys, index_type=ICL_INDEX_TYPE)
        else:
            icl_dset = None
            icl_indexer = None
            
        sbert=None
        if icl_indexer is not None:
            sbert = icl_indexer.sbert
            
        if IIA_TYPE == 'cross':
            iia_dset = iia_dsets[dset_lang]
            iia_indexer = SimpleDatasetIndexer(dataset=iia_dset, index_key=x_iia_keys, index_type=IIA_INDEX_TYPE, sbert=sbert)
        elif IIA_TYPE == 'mono':
            iia_dset = iia_dsets[dset_lang]
            iia_indexer = SimpleDatasetIndexer(dataset=iia_dset, index_key=iia_keys, index_type=IIA_INDEX_TYPE, sbert=sbert)
        else:
            iia_dset = None
            iia_indexer = None
                        
        ###
        # Sample Data
        ###
            
        inputs, preds, golds = [], [], []

        # Perform Sampling
        prompts, labels = [], []
        for e, sample in enumerate(eval_dset):
            if e < len(preds):
                continue

            if type(icl_keys) == str:
                input_query = sample[icl_keys]
            else: # type(icl_keys) == list
                input_query = [sample[key] for key in icl_keys]
            label = sample['label']

            ###
            # Retrieve Exemplars
            ###

            # Retrieve ICL Exemplars

            if icl_indexer is not None:
                icl_samples = icl_indexer.get_similar_samples(input_query, n_samples=ICL_EXEMPLAR_COUNT)
            else:
                icl_samples = None

            # Retrieve IIA Exemplars
            if iia_indexer is not None:
                iia_samples = iia_indexer.get_similar_samples(input_query, n_samples=IIA_EXEMPLAR_COUNT)
            else:
                iia_samples = None

            if IOA_TYPE == 'True':
                label_prompts = [f"{label} means {label_map[label]}" for label in label_names]
                label_prompts[-1] = f'and {label_prompts[-1]}'
                ioa_prompt = f'In {lang_map[dset_lang]} {", ".join(label_prompts) if len(label_prompts) > 2 else " ".join(label_prompts)}'
            elif IOA_TYPE == 'Target':
                for i in range(ICL_EXEMPLAR_COUNT):
                    icl_samples['label'][i] = label_map[icl_samples['label'][i]]
                ioa_prompt = None
            else:
                ioa_prompt = None

            ###
            # Prepare Zero-Shot / Few-Shot Prompt Text
            ###
            prompt_text = icl_prompter.generate_prompt(
                input_exemplar=sample,
                icl_exemplars=icl_samples,
                input_alignment_exemplars=iia_samples,
                output_alignment_prompt=ioa_prompt,
                alignment_language=lang_map[dset_lang]
            )

            prompts.append(prompt_text)
            labels.append(label)

            ###
            # Perform zero-shot / few-shot Inference
            ###

            # Batch Inference
            if len(prompts) == BATCH_SIZE:
                if IOA_TYPE in ['True', 'Target']:
                    print('IOA_TYPE', IOA_TYPE)
                    # Map label names from original label to target language label using label_map
                    ioa_labels = [label_map[label] for label in labels]
                    inputs = generate_input_label(prompts, ioa_labels)
                else:
                    inputs = generate_input_label(prompts, labels)

                for text_input in inputs:
                    print(text_input)
                    print('============')
                prompts, labels = [], [] 
                exit()
                # break
